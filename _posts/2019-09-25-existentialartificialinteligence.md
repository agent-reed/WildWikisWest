---
title: Existential risk from artificial intelligence
subtitle: Paralyzing information regarding the potential threat of creating intelligence artificially
date: 2019-09-25
link: https://en.wikipedia.org/wiki/Existential_risk_from_artificial_general_intelligence
linkText: the hypothesis that substantial progress in artificial general intelligence (AGI) could someday result in human extinction or some other unrecoverable global catastrophe.[1][2][3] It is argued that the human species currently dominates other species because the human brain has some distinctive capabilities that other animals lack. If AI surpasses humanity in general intelligence and becomes "superintelligent", then...
author: Andrew G
image: existentialriskai.jpg
tags:
---

{% include post.html %}

### Why it's wild

#### "A superintelligent machine would be as alien to humans as human thought processes are to cockroaches. Such a machine may not have humanity's best interests at heart; it is not obvious that it would even care about human welfare at all"

---